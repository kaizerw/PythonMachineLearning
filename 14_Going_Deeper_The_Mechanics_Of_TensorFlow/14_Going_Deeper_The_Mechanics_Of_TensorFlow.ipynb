{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Deeper - The Mechanics of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter, we trained a multilayer perceptron to classify MNIST digits, using various aspects of the TensorFlow Python API. That was a great way to dive us straight into some hands-on experience with TensorFlow neural network training and machine learning.\n",
    "\n",
    "In this chapter, we will now shift our focus squarely on to TensorFlow itself, and explore in detail the impressive mechanics and features that TensorFlow offers:\n",
    "\n",
    "* Key features and advantages of TensorFlow\n",
    "* TensorFlow ranks and tensors\n",
    "* Understanding and working with TensorFlow graphs\n",
    "* Working with TensorFlow variables\n",
    "* TensorFlow operations with different scopes\n",
    "* Common tensor transformations: working with ranks, shapes, and types\n",
    "* Transforming tensors as multidimensional arrays\n",
    "* Saving and restoring a model in TensorFlow\n",
    "* Visualizing neural network graphs with TensorBoard\n",
    "\n",
    "We will stay hands-on in this chapter, of course, and implement graphs throughout the chapter to explore the main TensorFlow features and concepts. Along the way, we will also revisit a regression model, explore neural network graph visualization with TensorBoard, and suggest some ways that you could explore visualizing more of the graphs that you will make through this chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keys features of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow gives us a scalable, multiplataform programming interface for implementing and running machine learning algorithms. The TensorFlow API has been relatively stable and mature since its 1.0 release in 2017. There are other deep learning libraries available, but they are still very experimental by comparison. \n",
    "\n",
    "A key feature of TensorFlow that we already noted is its ability to work with single or multiple GPUs. This allows users to train machine learning models very efficiently on large-scale systems. \n",
    "\n",
    "TensorFlow has strong growth drivers. Its development in funded and supported by Google, and so a large team of software engineers work on improvements continuosly. TensorFlow also has strong support from open source developers, who avidly contribute and provide user feedback. This has made the TensorFlow library more useful to both academic researchers and developers in their industry. A further consequence of these factors is that TensorFlow has extensive documentation and tutorials to help new users. \n",
    "\n",
    "Last but not least among these key features, TensorFlow supports mobile deployment, which makes it a very suitable tool for production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ranks and tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow library lets users define operations and functions over tensors as computational graphs. Tensors are a generalizable mathematical notation for multidimensional arrays holding data values, where the dimensionality of a tensor is typically referred to as its **rank**. \n",
    "\n",
    "We have worked mostly, so far, with tensors of rank zero to two. For instance, a scalar, a single number such as an integer or float, is a tensor of rank 0. A vector is a tensor of rank 1, and a matrix is a tensor of rank 2. But, it does not stop here. The tensor notation can be generalized to higher dimensions - as we will see in the next chapter, when we work with an input of rank 3 and weight tensors of rank 4 to support images with multiple color channels. \n",
    "\n",
    "To make the concept of a **tensor** more intuitive, consider the following figure, which represents tensors of ranks 0 and 1 in the first row, and tensors of ranks 2 and 3 in the second row:\n",
    "\n",
    "<img src='images/14_01.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get the rank and shape of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the *tf.rank* function to get the rank of a tensor. It is important to note that *tf.rank* will return a tensor as output, and in order to get the actual value, we will need to evaluate that tensor. \n",
    "\n",
    "In addition to the tensor rank, we can also get the shape of a TensoFlow tensor (similar to the shape of a NumPy array). For example, if $x$ is a tensor, we can get its shape using *x.get_shape()*, which will return an object of a special class called *TensorShape*.\n",
    "\n",
    "See the following examples on how to use the *tf.rank* function and the *get_shape* method of a tensor. The following code example illustrates how to retrieve the rank and shape of the tensor objects in a TensorFlow session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: () (4,) (2, 2)\n",
      "Ranks: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "## define the computation graph\n",
    "with g.as_default():\n",
    "    ## define tensors t1, t2, t3\n",
    "    t1 = tf.constant(np.pi)\n",
    "    t2 = tf.constant([1, 2, 3, 4])\n",
    "    t3 = tf.constant([[1, 2], [3, 4]])\n",
    "    \n",
    "    ## get their ranks\n",
    "    r1 = tf.rank(t1)\n",
    "    r2 = tf.rank(t2)\n",
    "    r3 = tf.rank(t3)\n",
    "    \n",
    "    ## get their shapes\n",
    "    s1 = t1.get_shape()\n",
    "    s2 = t2.get_shape()\n",
    "    s3 = t3.get_shape()\n",
    "    \n",
    "    print('Shapes:', s1, s2, s3)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('Ranks:', r1.eval(), r2.eval(), r3.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the rank of the *t1* tensor is 0 since it is just a scalar (corresponding to the *[]* shape). The rank of the *t2* vector is 1, and since it has four elements, its shape is the one-element tuple *(4, )*. Lastly, the shape of the $2 \\times 2$ matrix *t3* is  2; thus, its corresponding shape is given by the *(2, 2)* tuple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding TensorFlow's computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow relies on building a computation graph at its core, and it uses this computation graph to derive relationships between tensors from the input all the way to the output. Let's say, we have rank 0 (scalars) and tensors *a*, *b*, and *c* and we want to evaluate $z = 2 \\times (a - b) + c$. This evaluation can be represented as a computation graph, as shown in the following figure: \n",
    "\n",
    "<img src='images/14_02.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the computation graph is simply a network of nodes. Each node resembles an operation, which applies a function to its input tensor or tensors and returns zero or more tensors as the output. \n",
    "\n",
    "TensorFlow builds this computation graph and uses it to compute the gradients accordingly. The individual steps for building and compiling such a computation graph in TensorFlow are as follows: \n",
    "\n",
    "1. Instantiate a new, empty computation graph. \n",
    "2. Add nodes (the tensors and operations) to the computation graph. \n",
    "3. Execute the graph:\n",
    "    1. Start a new session\n",
    "    2. Initialize the variables in the graph\n",
    "    3. Run the computation graph in this session\n",
    "   \n",
    "So, let's create a graph for evaluating $z = 2 \\times (a - b) + c$, as shown in the previous figure, where *a*, *b*, and *c* are scalars (single numbers). Here, we define them as TensorFlows constants. A graph can be created by calling *tf.Graph()*, then nodes can be added to it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "    \n",
    "    z = 2*(a-b) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we added nodes to the *g* graph using *with g.as_default()*. If we do not explicitly create a graph, there is always a default graph, and therefore, all the nodes are added to the default graph. In this book, we try to avoid working with the default graph for clarity. This approach is specially useful when we are developing code in a Jupyter notebook, as we avoid pilling up unwanted nodes in the default graph by accident. \n",
    "\n",
    "A TensorFlow session is an environment in which the operations and tensors of a graph can be executed. A session object is created by calling *tf.Session* that can receive an existing graph (here, *g*) as an argument, as in *tf.Session(graph=g)*, otherwise, it will launch the default graph, which might be empty. \n",
    "\n",
    "After launching a graph in a TensorFlow session, we can execute it nodes; that is, evaluating its tensors or executing its operators. Evaluating each individual tensor involves calling its *eval* method inside the current session. When evaluating a specific tensor in the graph, TensorFlow has to execute all the preceding nodes in the graph until it reaches that particular one. In case there are one or more placeholders, they would need to be fed, as we will see later in the next section. \n",
    "\n",
    "Quite similarly, executing operations can be done using a session's *run* method. In the previous example, *train_op* is an operator that does not return any tensor. This operator can be executed as *train_op.run()*. Furthermore, there is a universal way of runnning both tensors and operators: *tf.Session().run()*. Using this method, as we will see later on as well, multiple tensors and operators can be placed in a list or tuple. As a result, *tf.Session().run()* will return a list or tuple of the same size. \n",
    "\n",
    "Here, we will launch the previous graph in a TensorFlow session and evaluate the tensor *z* as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we define tensors and operations in a computation graph context within TensorFlow. A TensorFlow session is then used to execute the operations in the graph and fetch and evaluate the results. \n",
    "\n",
    "In this section, we saw how to define a computation graph, how to add nodes to it, and how to evaluate the tensors in a graph within a TensorFlow session. We will now take a deeper look into the different types of nodes that can appear in a computation graph, including placeholders and variables. Along the way, we will see some other operators that do not return a tensor as the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has special mechanisms for feeding data. One of these mechanisms is the use of placeholders, which are predefined tensors with specific types and shapes. \n",
    "\n",
    "These tensors are added to the computation graph using the *tf.placeholder* function, and they do not contain any data. However, upon the execution of certain nodes in the graph, these placeholders need to be fed with data arrays. \n",
    "\n",
    "In the following sections, we will see how to define placeholders in a graph and how to feed them with data values upon execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you now know, placeholders are defined using the *tf.placeholder* function. When we define placeholders, we need to decide what their shape ant type should be, according to the shape and type of the data that will be fed through them upn execution. \n",
    "\n",
    "Let's start with a simple example. In the following code, we will define the same graph that was shown in the previous section for evaluating $z = 2 \\times (a-b) + c$. This times, however, we use placeholders for the scalars *a*, *b*, and *c*. Also, we store the intermediate tensors associated with *r1* and *r2*, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_a = tf.placeholder(tf.int32, shape=[], name='tf_a')\n",
    "    tf_b = tf.placeholder(tf.int32, shape=[], name='tf_b')\n",
    "    tf_c = tf.placeholder(tf.int32, shape=[], name='tf_c')\n",
    "    \n",
    "    r1 = tf_a - tf_b\n",
    "    r2 = 2*r1\n",
    "    z = r2 + tf_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we defined three placeholders, named *tf_a*, *tf_b*, and *tf_c*, using type *tf.int32* (32-bit integers) and set their shape via *shape=[]* since they are scalars (tensors of rank 0). In the current book, we always precede the placeholder objects with *tf_* for clarity and to be able to distinguish them from the other tensors. \n",
    "\n",
    "Note that in the previous code example, we were dealing with scalars, and therefore, their shapes were specified as *shape=[]* However, it is very straightforward to define placeholders of higher dimensions. For example, a rank 3 placeholder of type *float* and shape $3 \\times 4 \\times 5$ can be defined as *tf.placeholder(dtype=tf.float32, shape=[2, 3, 4])*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding placeholders with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we execute a node in the graph, we need to create a Python **dictionary** to feed the values of placeholders with data arrays. We do this according to the type and shape of the placeholders. This dictionary is passed as the input argument *feed_dict* to a session's *run* method. \n",
    "\n",
    "In the previous graph, we added three placeholders of the type *tf.int32* to feed scalars for computing *z*. Now, in order to evaluate the result tensor *z*, we can feed arbitrary integer values (here, 1, 2, and 3) to the placeholders, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    feed = {tf_a: 1, tf_b: 2, tf_c: 3}\n",
    "    print('z:', sess.run(z, feed_dict=feed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that having extra arrays for placeholders does not cause any error; it is just redundant to do so. However, if a placeholder is needed for the execution of a particular node, and is not provided via the *feed_dict* argument, it will cause a runtime error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining placeholders for data arrays with varying batchsizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, when we are developing a neural network model, we may deal with mini-batches of data that have different sizes. For example, we may train a neural network with a specific mini-batch size, but we want to use the network to make predictions on one or more data point. \n",
    "\n",
    "A useful feature of placeholders is that can specify *None* for the dimension that is varying in size. For example, we can create a placeholder of rank 2, where the first dimension is unknown (or may vary), as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, \n",
    "                          shape=[None, 2], \n",
    "                          name='tf_x')\n",
    "    \n",
    "    x_mean = tf.reduce_mean(tf_x, axis=0, name='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can evaluate *x_mean* with two different input, *x1* and *x2*, which are NumPy arrays of shape *(5, 2)* and *(10, 2)*, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape  (5, 2)\n",
      "Result: [0.62 0.47]\n",
      "Feeding data with shape  (10, 2)\n",
      "Result: [0.46 0.49]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    x1 = np.random.uniform(low=0, high=1, size=(5, 2))\n",
    "    print('Feeding data with shape ', x1.shape)\n",
    "    print('Result:', sess.run(x_mean, feed_dict={tf_x: x1}))\n",
    "    \n",
    "    x2 = np.random.uniform(low=0, high=1, size=(10, 2))\n",
    "    print('Feeding data with shape ', x2.shape)\n",
    "    print('Result:', sess.run(x_mean, feed_dict={tf_x: x2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if we try printing the object *tf_x*, we will get *Tensor(\"tf_x:0\", shape=(?, 2), dtype=float32)*, which shows that the shape of this tensor is *(?, 2)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of TensorFlow, variables are a special type of tensor objects that allow us to store and update the parameters of our models in a TensorFlow session during training. The following sections explain how we can define variables in a graph, initialize those variables in a session, organize variables via the so-called variable scope, and reuse existing variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow variables store the parameters of a model than can be updated during training, for example, the weights in the input, hidden and output layers of a neural network. When we define a variable, we need to initialize it with a tensor of values. \n",
    "\n",
    "TensorFlow provides two ways for dealing with variables: \n",
    "* *tf.Variable(<initial-value>, name='variable-name')*\n",
    "* *tf.get_variable(name, ...)*\n",
    "\n",
    "The first one, *tf.Variable*, is a class that creates an object for a new variable and adds it to the graph. Note that *tf.Variable* does not have an explicit way to determine *shape* and *dtype*; the shape and type are set to be the same as those of the initial values. \n",
    "\n",
    "The second option, *tf.get_variable*, can be used to **reuse** an existing variable with a given name (if the name exists in the graph) or create a new one if the name does not exist. In this case, the name becomes critical; that is probably why it has to be placed as the first argument to this function. Furthermore, *tf.get_variable* provides an explicit way to set *shape* and *dtype*; these parameters are only required when creating a new variable, not reusing existing ones. \n",
    "\n",
    "The advantage of *tf.get_variable* over *tf.Variable* is twofold: *tf.get_variable* allows us to reuse existing variables and it already uses the popular Xavier/Glorot initialization scheme by default. Besides the initializer, the *get_variable* function provides other parameters to control the tensor, such as adding a regularizer for the variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xavier/Glorot initialization**\n",
    "\n",
    "In the early development of deep learning, it was observed that random uniform or random normal weight initialization could often result in a poor performance of the model during training. \n",
    "\n",
    "In 2010, Xavier Glorot and Yoshua Bengio investigated the effect of initialization and proposed a novel, more robust initialization scheme to facilitate the training of deep networks. \n",
    "\n",
    "The general idea behind Xavier initialization is to roughly balance the variance of the gradients across different layers. Otherwise, one layer may get too much attention during training while the other layer lags behind. \n",
    "\n",
    "According to the research paper by Glorot and Bengio, if we want to initialize the weights from uniform distribution, we should choose the interval of this uniform distribution as follows: \n",
    "\n",
    "$$W ~ Uniform \\left(-\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}} \\right)$$\n",
    "\n",
    "Here, $n_{in}$ is the number of input neurons that are multiplied with the weights, and $n_{out}$ is the number of output neurons that feed into the next layer. For initializing the weights from Gaussian (normal) distribution, the authors recommended choosing the standard deviation of this Gaussian to be $\\sigma = \\frac{\\sqrt{2}}{\\sqrt{n_{in} + n_{out}}}$.\n",
    "\n",
    "TensorFlow support Xavier initialization in both uniform and normal distributions of weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either initialization technique, it is important to note that the initial values are not set until we launch the graph in *tf.Session* and explicitly run the initializer operator in that session. In fact, the required memory for a graph is not allocated until we initialize the variables in a TensorFlow session. \n",
    "\n",
    "Here is an example of creating a variable object where the initial values are created from a NumPy array. The *dtype* data type of this tensor is *tf.int64*, which is automatically **inferred** from its NumPy array input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1, 2, 3, 4], \n",
    "                              [5, 6, 7, 8]]), name='w')\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is critical to understand that tensors defined as variables are not allocated in memory and contain no values until they are initialized. Therefore, before executing any node in the computation graph, we *must* initialize the variables that are within the path to the node that we want to execute. \n",
    "\n",
    "This initialization process refers to allocating memory for the associated tensors and assigning their initial values. TensorFlow provides a function named *tf.global_variables_initializer* that returns an operator for initializing all the variables that exist in a computation graph. Then, executing this operator will initialize the variables as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store this operator in an object such as *init_op = tf.global_variables_initializer()* and execute this operator later using *sess.run(init_op)* or *init_op.run()*. However, we need to make sure that this operator is created after we define all the variables. \n",
    "\n",
    "For example, in the following code, we define the variable *w1*, then we define the operator *init_op*, followed by the variable *w2*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(1, name='w1')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    w2 = tf.Variable(2, name='w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's evaluate *w1* as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w1:', sess.run(w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works fine. Now, let's try evaluating *w2*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c10f8d6b307c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w2:', sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the code example, executing the graph raises an error because *w2* was not initialized via *sess.run(init_op)*, and therefore, could not be evaluated. The operator *init_op* was defined prior to adding *w2* to the graph; thus, executing *init_op* will not initialize *w2*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we are going to discuss *scoping*, which is an important concept in TensorFlow, and especially useful if we are constructing large neural network graphs. \n",
    "\n",
    "With variable scopes, we can organize the variables into separate subparts. When we create a variable scope, the name of operations and tensors that are created within that scope are prefixed with that scope, and those scopes can further be nested. For example, if we have two subnetworks, where each subnetwork has several layers, we can define two scopes named *'net_A'* and *'net_B'*, respectively. Then, each layer will be defined within one of these scopes. \n",
    "\n",
    "Let's see how the variable names will turn out in the following code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'net_A/layer-1/weights:0' shape=(10, 4) dtype=float32_ref>\n",
      "<tf.Variable 'net_A/layer-2/weights:0' shape=(20, 10) dtype=float32_ref>\n",
      "<tf.Variable 'net_B/layer-1/weights:0' shape=(10, 4) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    with tf.variable_scope('net_A'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w1 = tf.Variable(tf.random_normal(shape=(10, 4)), name='weights')\n",
    "        with tf.variable_scope('layer-2'):\n",
    "            w2 = tf.Variable(tf.random_normal(shape=(20, 10)), name='weights')\n",
    "    with tf.variable_scope('net_B'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w3 = tf.Variable(tf.random_normal(shape=(10, 4)), name='weights')\n",
    "        \n",
    "    print(w1)\n",
    "    print(w2)\n",
    "    print(w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the variables names are now prefixed with their nested scopes, separated by the forward slash *'/'* symbol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine that we are developing a somewhat complex neural network model that has a classifier whose input data comes from more than once source. For example, we will assume that we have data $(X_A, y_A)$ coming from source $A$ and data $(X_B, y_B)$ comes from the source $B$. In this example, we will design our graph in such a way that it will use the data from only one source as input tensor to build the network. Then, we can feed the data from the other source to the same classifier. \n",
    "\n",
    "In the following example, we assume that data from source $A$ is fed through placeholder, and source $B$ is the output of a generator network. We will build by calling the *build_generator* function within the *generator* scope, then we will add a classifier by calling *build_classifier* within the *classifier* scope: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    weights = tf.get_variable(name='weights', \n",
    "                              shape=(data_shape[1], \n",
    "                                     n_classes), \n",
    "                              dtype=tf.float32)\n",
    "    bias = tf.get_variable(name='bias', \n",
    "                           initializer=tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weights), bias, name='logits')\n",
    "    return logits, tf.nn.softmax(logits)\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    w1 = tf.Variable(tf.random_normal(shape=(data_shape[1], n_hidden)), name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(shape=n_hidden), name='b1')\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1, name='hidden_pre-activation')\n",
    "    hidden = tf.nn.relu(hidden, 'hidden_activation')\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_normal(shape=(n_hidden, data_shape[1])), name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(shape=data_shape[1]), name='b2')\n",
    "    \n",
    "    output = tf.add(tf.matmul(hidden, w2), b2, name='output')\n",
    "    return output, tf.nn.sigmoid(output)\n",
    "\n",
    "batch_size = 64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), \n",
    "                          dtype=tf.float32, \n",
    "                          name='tf_X')\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "    \n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        cls_out1 = build_classifier(data=tf_X, \n",
    "                                    labels=tf.ones(shape=batch_size))\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have called the *build_classifier* function two times. The first call causes the building of the network. Then, we call *scope.reuse_variables()* and call that function again. As a result, the second call does not create new variables; instead, it reuses the same variables. Alternatively, we could reuse the variables by specifying the *reuse=True* parameter, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), \n",
    "                          dtype=tf.float32, \n",
    "                          name='tf_X')\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "    \n",
    "    with tf.variable_scope('classifier'):\n",
    "        cls_out1 = build_classifier(data=tf_X, \n",
    "                                    labels=tf.ones(shape=batch_size))\n",
    "        \n",
    "    with tf.variable_scope('classifier', reuse=True):\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have discussed how to define computational graphs and variables in TensorFlow, a detailed discussion of how we can compute gradients in a computational graph is beyond the scope of this book, where we use TensorFlow's convenient optimizer classes that perform backpropagation automatically for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulding a regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have explored placeholders and variables, let's build an example model for regression analysis, similar to the one we created in previous chapter, where our goal is to implement a linear regression model: $ŷ = wx + b$. \n",
    "\n",
    "In this model, $w$ and $b$ are the two parameters of this simple regression model that need to be defined as variables. Note that $x$ is the input of the model, which we can define as placeholder. Furthermore, recall that for training this model, we need to formulate a cost function. Here, we use the **Mean Squared Error (MSE)** cost function:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^n \\left(y^{(i)}-ŷ^{(i)}\\right)^2$$\n",
    "\n",
    "Here, $y$ is the true value, which is given as the input to this model for training. Therefore, we need to define $y$ as a placeholder as well. Finally, $ŷ$ is the prediction output, which will be computed using TensorFlow operations - *tf.matmul* and *tf.add*. Recall that TensorFlow operations return zero or more tensors; here, *tf.matmul* and *tf.add* return one tensor. \n",
    "\n",
    "We can also use the overloaded operator *+* for adding two tensors; however, the advantage of *tf.add* is that we can provide an additional name for the resulting tensor via the *name* parameter. \n",
    "\n",
    "So, let's summarize all our tensors with their mathematical notations and coding naming, as follows:\n",
    "\n",
    "* Input $x$: *tf_x* defined as a placeholder\n",
    "* Input $y$: *tf_y* defined as a placeholder\n",
    "* Model parameter $w$: *weight* defined as a variable\n",
    "* Model parameter $b$: *bias* defined as a variable\n",
    "* Model output $$ŷ: $y_hat* returned by the TensorFlow operations to compute the prediction using the regression model\n",
    "\n",
    "The code to implement this simple regression model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(123)\n",
    "    ## placeholders\n",
    "    tf_x = tf.placeholder(shape=(None), \n",
    "                          dtype=tf.float32, \n",
    "                          name='tf_x')\n",
    "    tf_y = tf.placeholder(shape=(None), \n",
    "                          dtype=tf.float32, \n",
    "                          name='tf_y')\n",
    "    \n",
    "    ## define the variable (model parameters)\n",
    "    weight = tf.Variable(tf.random_normal(shape=(1, 1), \n",
    "                                          stddev=0.25), \n",
    "                         name='weight')\n",
    "    bias = tf.Variable(0.0, name='bias')\n",
    "    \n",
    "    ## build the model\n",
    "    y_hat = tf.add(weight * tf_x, bias, name='y_hat')\n",
    "    \n",
    "    ## compute the cost\n",
    "    cost = tf.reduce_mean(tf.square(tf_y - y_hat), name='cost')\n",
    "    \n",
    "    ## train the model\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optim.minimize(cost, name='train_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built the graph, our next steps are to create a session to launch the graph and train the model. But before we go further, let's see how we can evaluate tensors and execute operations. We will create a random regression data with one feature, using the *make_random_data* function and visualizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZ//SR7jKsorAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create a random toy dataset for regression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=4, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, scale=(0.5 + t*t/3), \n",
    "                             size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x-0.84 + np.array(y)\n",
    "\n",
    "X, y = make_random_data()\n",
    "\n",
    "plt.plot(X, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready; let's train the previous model. Let's start by creating a TensorFlow session object called *sess*. Then, we want to initialize our variables which, as we saw, we can do with *sess.run(tf.global_variables_initializer())*. After this, we can create a *for* loop to execute the train operator and calculate the training cost at the same time. \n",
    "\n",
    "So let's combine the two tasks, the first to execute an operator, and the second to evaluate a tensor, into one *sess.run* method call. The code for this is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: 12.2230\n",
      "Epoch   50: 8.3876\n",
      "Epoch  100: 6.5721\n",
      "Epoch  150: 5.6844\n",
      "Epoch  200: 5.2269\n",
      "Epoch  250: 4.9725\n",
      "Epoch  300: 4.8169\n",
      "Epoch  350: 4.7119\n",
      "Epoch  400: 4.6347\n",
      "Epoch  450: 4.5742\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHutJREFUeJzt3XmUXHWd9/H3t5be93R10kln38lK\n0oRAkCCbEZFNUDiAeIaZOOoo+sx5VMZnHh115ujoiD6DCxlhcBRxYVWQfZe9QwJJCFkhpLN1d3rv\nTu+/54+qhE5n63RV96269XmdU+fW/dVN3e+vKT5163c3c84hIiKpL+B1ASIikhgKdBERn1Cgi4j4\nhAJdRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuIToZFcWWlpqZs0adJIrlJEJOWtXr26zjkX\nOdFyIxrokyZNoqqqaiRXKSKS8sxsx2CW05CLiIhPKNBFRHxCgS4i4hMKdBERn1Cgi4j4hAJdRMQn\nFOgiIj6REoH+zKYafvbsVq/LEBFJaikR6C9v28+Pn9xCZ0+v16WIiCStlAj0RROK6OrpY8PuZq9L\nERFJWicMdDO7w8xqzGx9v7YfmNk7ZvaWmd1vZkXDWeSiCcUAvLGjYThXIyKS0gazhX4nsGJA2xPA\nXOfcfGAzcHOC6zpMWUEW40uyeeN9BbqIyLGcMNCdc88D9QPaHnfO9cRmXwEqhqG2wyyaUMzqHQ04\n54Z7VSIiKSkRY+h/AzySgPc5rsUTi9nX3MmuxgPDvSoRkZQUV6Cb2TeAHuCu4yyz0syqzKyqtrZ2\nyOs6NI7+fuOQ30NExM+GHOhmdgNwMXCtO844iHNulXOu0jlXGYmc8PrsxzRrTD7Z4aB2jIqIHMOQ\nbnBhZiuArwHLnXPtiS3p6ELBAAvHF7FagS4iclSDOWzxbuBlYKaZVZvZjcCtQD7whJmtNbNfDHOd\nACyaWMTbe5pp7+o58cIiImnmhFvozrlrjtJ8+zDUckKLJxbT2+d4q7qJpVNGeVGCiEjSSokzRQ86\ndXx0x6iGXUREjpRSgV6cm8GUSC5rdIKRiMgRUirQARbrBCMRkaNKuUA/bVIJDe3dbK1p9boUEZGk\nknKBvmRyCQCvvlt/giVFRNJLygX6xFE5lOVn8poCXUTkMCkX6GbGksklvPZuvcbRRUT6SblABzh9\nyij2Nnews14X6hIROSg1Az02jv7Ku/s9rkREJHmkZKBPi+RRnBPWOLqISD8pGeiBgHHapBIFuohI\nPykZ6BA9fPH9+nb2NGkcXUQEUjjQT58cvTiXttJFRKJSNtBPGVtAXmZIJxiJiMSkbKAHA0blpGJt\noYuIxKRsoEN0HH1rTSu1LZ1elyIi4rmUDvRlU0sBeGlbnceViIh4bzC3oLvDzGrMbH2/tqvMbIOZ\n9ZlZ5fCWeGxzxxVSkBXipa06wUhEZDBb6HcCKwa0rQeuAJ5PdEEnIxgwlk4ZxYvaQhcROXGgO+ee\nB+oHtG10zm0atqpOwrJppVQ3HOD9/e1elyIi4qmUHkOHaKAD/HWrttJFJL0Ne6Cb2UozqzKzqtra\n2oS//9RILqMLMjXsIiJpb9gD3Tm3yjlX6ZyrjEQiCX9/M2PZ1FJe3rafvj5dH11E0lfKD7kAnDmt\nlPq2Lt7Z2+J1KSIinhnMYYt3Ay8DM82s2sxuNLPLzawaOAN42MweG+5Cj2fZtOh1XXQ8uoiks9CJ\nFnDOXXOMl+5PcC1DVl6YzZRILi9ureNvPzTF63JERDzhiyEXiJ41+uq79XT39nldioiIJ3wT6GdN\nL6W9q5fVOxq8LkVExBO+CfQzp44iFDCe25z4QyNFRFKBbwI9PytM5aRint2kQBeR9OSbQAdYPqOM\njXua2dfc4XUpIiIjzleBfs7M6IlLGnYRkXTkq0CfNSaf0QWZCnQRSUu+CnQzY/mMCC9srqVHhy+K\nSJrxVaBDdBy9uaOHN6sbvS5FRGRE+S7Qz5peSjBgOtpFRNKO7wK9MDvMqeOLNI4uImnHd4EO0aNd\n3qpuoral0+tSRERGjC8D/cOzygB45p0ajysRERk5vgz0U8oLGFeUzRMb93ldiojIiPFloJsZ588u\n44UttXR093pdjojIiPBloAOcf8poOrr7eFE3jxaRNOHbQD998ijyMkM88baGXUQkPQzmFnR3mFmN\nma3v11ZiZk+Y2ZbYtHh4yzx5GaEAy2dGeHJjjW4eLSJpYTBb6HcCKwa0fR14yjk3HXgqNp90Ljxl\nNHWtnTprVETSwgkD3Tn3PFA/oPlS4Fex578CLktwXQlxzowyggHjSR3tIiJpYKhj6KOdc3sAYtOy\nYy1oZivNrMrMqmprR/bszcKcMEsmlWgcXUTSwrDvFHXOrXLOVTrnKiORyHCv7gjnnzKazftaea+u\nbcTXLSIykoYa6PvMrBwgNk3aUzI/Mmc0AI9u2OtxJSIiw2uogf4n4IbY8xuABxNTTuJVFOewoKKQ\nv6zb43UpIiLDajCHLd4NvAzMNLNqM7sR+B5wgZltAS6IzSeti+aV81Z1Ezvr270uRURk2AzmKJdr\nnHPlzrmwc67COXe7c26/c+4859z02HTgUTBJ5aNzywF4dL2GXUTEv3x7pmh/E0blMHdcAQ9r2EVE\nfCwtAh2iwy5rdzayq/GA16WIiAyLtAl0DbuIiN+lTaBPLs1ldnmBjnYREd9Km0AH+Ni8Maze0cCe\nJg27iIj/pFegzx8LwENvaitdRPwnrQJ9cmkuCyoKeWDtLq9LERFJuLQKdIBLF45jw+5mtta0eF2K\niEhCpV2gX7ygnIDBA2t2e12KiEhCpV2gl+VnsWxaKQ++uQvndCcjEfGPtAt0iA677Kw/wBvvN3hd\niohIwqRloH9kzmgyQwENu4iIr6RloOdnhTn/lNE8vG4P3b19XpcjIpIQaRnoAJcvHEd9WxfPbx7Z\n2+KJiAyXtA305TMjlOZl8IeqnV6XIiKSEGkb6OFggCsWVfDUxhrqWju9LkdEJG5xBbqZ3WRm681s\ng5l9OVFFjZSrFlfQ0+d4YI3OHBWR1DfkQDezucDfAUuABcDFZjY9UYWNhOmj8zl1QhG/f32njkkX\nkZQXzxb6bOAV51y7c64HeA64PDFljZxPVo5nS00rb1Y3eV2KiEhc4gn09cDZZjbKzHKAi4DxiSlr\n5Fw8v5yscEA7R0Uk5Q050J1zG4HvA08AjwJvAj0DlzOzlWZWZWZVtbXJd4hgflaYi+aV8+e1uznQ\n1et1OSIiQxbXTlHn3O3OuUXOubOBemDLUZZZ5ZyrdM5VRiKReFY3bD5VOZ6Wzh7dRFpEUlq8R7mU\nxaYTgCuAuxNR1EhbMrmEqZFcfvPKDq9LEREZsniPQ7/XzN4G/gx8wTmXkle7MjOuXzqRtTsbWaed\noyKSouIdcvmQc+4U59wC59xTiSrKC1csriA7HNRWuoikrLQ9U3Sggqwwl506lgff3EXTgW6vyxER\nOWkK9H6uWzqRju4+7l1d7XUpIiInTYHez5yxhSyaUMRvXtmhM0dFJOUo0Ae4bulEtte18eLW/V6X\nIiJyUhToA1w0r5zSvAzuePFdr0sRETkpCvQBssJBrl86iaffqWFrTavX5YiIDJoC/SiuWzqBjFBA\nW+kiklIU6EcxKi+TTywax72rq6lv6/K6HBGRQVGgH8PfLJtMZ08fd+lEIxFJEQr0Y5g+Op9zZkb4\n1cs76OzRVRhFJPkp0I/jb8+aQl1rp25RJyIpQYF+HMumjWLO2AJ+8dx2evt0opGIJDcF+nGYGV/4\n8DTerWvjL7pWuogkOQX6CayYM4apkVx++sxWXQ5ARJKaAv0EAgHj8+dM4529LTy1scbrckREjkmB\nPgiXLBxLRXE2t2orXUSSmAJ9EMLBAJ9dPpW1Oxt5aZsu2iUiySnee4p+xcw2mNl6M7vbzLISVViy\nuWpxBaMLMrnlic3aSheRpDTkQDezccCXgErn3FwgCFydqMKSTVY4yBfPnU7Vjgae3VzrdTkiIkeI\nd8glBGSbWQjIAXbHX1Ly+mTleCqKs/mPxzdpK11Eks6QA905twv4IfA+sAdocs49nqjCklFGKMBN\n501n/a5mHtuwz+tyREQOE8+QSzFwKTAZGAvkmtl1R1lupZlVmVlVbW3qD1Vcfuo4pkRy+dETm3T2\nqIgklXiGXM4H3nXO1TrnuoH7gDMHLuScW+Wcq3TOVUYikThWlxxCwQBfOX8Gm/e18uc3fT3CJCIp\nJp5Afx9YamY5ZmbAecDGxJSV3D42r5w5Ywv4wWOb6OjWlRhFJDnEM4b+KnAP8AawLvZeqxJUV1IL\nBIxvXDSbXY0HuPOl97wuR0QEiPMoF+fcN51zs5xzc51z1zvnOhNVWLI7c1op584q46dPb9VdjUQk\nKehM0Tj800WzaO/u5SdPbva6FBERBXo8ppXlc/Vp47nr1ffZVtvqdTkikuYU6HH6ygUzyAoH+e5D\nb+tkIxHxlAI9TqV5mdx03nSe2VTLk7q8roh4SIGeAJ9ZNonpZXn8y5836DBGEfGMAj0BwsEA3750\nLtUNB/jZs9u8LkdE0pQCPUHOmDqKSxaM5RfPbWPH/javyxGRNKRAT6BvfGw24YDxfx5Yrx2kIjLi\nFOgJNLogi6+umMULW+q4941dXpcjImlGgZ5g1y+dSOXEYr7z0NvUtHR4XY6IpBEFeoIFAsb3r5zP\nge5evvngBq/LEZE0okAfBlMjedx03nQeWb+XR9bt8bocEUkTCvRhsvLsKcwZW8A/P7iBxnZdvEtE\nhp8CfZiEgwG+/4n5NLZ38U/3r9NRLyIy7BTow2juuEL+14Uz+Mu6vdyzutrrckTE5xTow+yzZ0/l\n9MklfOtPG3TCkYgMKwX6MAsGjFs+tZBgwLjpd2vp7u3zuiQR8akhB7qZzTSztf0ezWb25UQW5xdj\ni7L5tyvmsXZnI//51BavyxERnwoN9R865zYBCwHMLAjsAu5PUF2+c/H8sTzzTi23PrOVJZNHcdb0\nUq9LEhGfSdSQy3nANufcjgS9ny9957I5TCvL40u/W8PuxgNelyMiPpOoQL8auPtoL5jZSjOrMrOq\n2traBK0uNeVkhPj5dYvp6unj83e9QVePxtNFJHHiDnQzywAuAf54tNedc6ucc5XOucpIJBLv6lLe\n1EgeP7hyPmt3NvLdh9/2uhwR8ZFEbKF/FHjDObcvAe+VFj46r5yVZ0/hf17ewf1rdHy6iCRGIgL9\nGo4x3CLH9tWPzGTplBK+du86Vu+o97ocEfGBuALdzHKAC4D7ElNO+ggFA/z82sWMLcxi5f+sZmd9\nu9cliUiKiyvQnXPtzrlRzrmmRBWUTopzM7j9M6fR3dvHjb96neaObq9LEpEUpjNFPTY1kscvrlvM\n9to2/uG3a+jRmaQiMkQK9CRw5rRSvnvZXJ7fXMvN9+nKjCIyNEM+U1QS6+olE9jT1MFPntpCSW4G\nN1802+uSRCTFKNCTyJfPn05Dexe3Pb+d4twM/n75VK9LEpEUokBPImbGtz4+h4b2br73yDsUZYe5\neskEr8sSkRShQE8ygYDxH1ctoPlANzffv45QMMCViyu8LktEUoB2iiahjFCA265fzLKppfzve97k\nj1U7vS5JRFKAAj1JZYWD/PKGSs6aVspX732LPyjUReQEFOhJLCsc5L8+HQ31r937Fne/9r7XJYlI\nElOgJ7mDob58RoSb71vHz57dquPUReSoFOgpICscZNX1lVy6cCz//ugmvvvwRvr6FOoicjgd5ZIi\nMkIBbvnkQopzMrj9r+9S39bF9z8xn4yQvpNFJEqBnkICAeObHz+F0rwMfvj4ZvY0HeAX1y2mKCfD\n69JEJAlo8y7FmBn/cO50bvnUAt7Y0chlP32RbbWtXpclIklAgZ6iLj+1gt/+3em0dPRw+U9f5K9b\n6rwuSUQ8pkBPYZWTSnjgC8sYU5jFp+94lZ89u1U7S0XSWLx3LCoys3vM7B0z22hmZySqMBmc8SU5\n3Pf5ZXx0Xjn//ugmVv66iqZ23ShDJB3Fu4X+E+BR59wsYAGwMf6S5GTlZYa49ZpT+dbHT+G5zbVc\nfOsLrN+lm0iJpJshB7qZFQBnA7cDOOe6nHONiSpMTo6Z8Zllk/n9Z8+gt9dxxc9e4pcvbNcQjEga\niWcLfQpQC/y3ma0xs1+aWW6C6pIhWjShmIe+9CHOnhHhuw9v5NpfvsruxgNelyUiIyCeQA8Bi4Cf\nO+dOBdqArw9cyMxWmlmVmVXV1tbGsToZrJLcDP7r04v53hXzeLO6kY/8+HkeXLvL67JEZJjFE+jV\nQLVz7tXY/D1EA/4wzrlVzrlK51xlJBKJY3VyMsyMq5dM4JGbPsT0sjxu+t1aPvvrKvY2dXhdmogM\nkyEHunNuL7DTzGbGms4D3k5IVZIwE0fl8ofPnsHXVszi2U21XPCj5/j1Kzs0ti7iQ/Ee5fJF4C4z\newtYCPxb/CVJooWCAT53zlQe/8rZLBhfxD8/sJ6rbnuZTXtbvC5NRBLIRvJSrJWVla6qqmrE1idH\ncs5x/5pdfOeht2nu6OHa0yfwlfNnUJyr68GIJCszW+2cqzzRcjpTNM2YGVcsquDpfzyHa0+fwG9e\n2cE5P3yWO198l+7ePq/LE5E4KNDTVHFuBt++dC5/uelDzB1XwLf+/DYrfvw8j6zboxtoiKQoBXqa\nmzWmgN/ceDqrrl8MwOfueoNLbn2RZzfVKNhFUowCXTAzLpwzhse+fDY/vGoB9W1dfOa/X+dTt73C\nK9v3K9hFUoR2isoROnt6+f3rO/nPp7dS29LJ4onFfG75VM6dVUYgYF6XJ5J2BrtTVIEux3Sgq5c/\nVO1k1fPb2dV4gJmj8/n7c6Zw8fyxhIP6cScyUhTokjDdvX089NZufv7sNjbva6W8MItrT5/A1Usm\nUJqX6XV5Ir6nQJeE6+tzPLOphjtfeo8XttSREQzwsfnlXH/GRE4dX4SZhmNEhsNgA103iZZBCwSM\n82aP5rzZo9la08pvXtnBPauruX/NLuaNK+STp43nkvljKcwJe12qSFrSFrrEpbWzh/vX7OKuV3bw\nzt4WMkIBLjxlNFcuruBD0yMEtRNVJG4acpER5Zxjw+5m7lldzQNrd9HY3s3ogkwuXTiOi+aVs6Ci\nUEMyIkOkQBfPdPb08vTGGu5ZXc1zm2vp6XNUFGdz0bxyPjavnPkKd5GTokCXpNDU3s3jb+/l4XV7\n+OuWukPhvmLOGM6bPZrKScU6BFLkBBToknT6h/tLW/fT1dtHflaI5TMinDe7jOUzyijRVR9FjqBA\nl6TW1tnDX7fW8fTGGp7eVENtSycBgwXjizhrWilnTi1l0cQiMkNBr0sV8ZwCXVJGX59j/e4mntxY\nwwtbanmruonePkdWOMBpk0o4c2opy6aNYs7YQh01I2lJgS4pq7mjm9e21/Pitjpe2rqfTfuid1bK\nzwyxcEIRlRNLqJxUzMLxReRm6lQK8b8RCXQzew9oAXqBnhOtUIEuQ1Hb0slL2+p4/b16qt5rYNO+\nFpyDYMCYXZ7P4gnFLJpYzPyKIiaW5OgCYuI7Ixnolc65usEsr0CXRGju6GbN+42sfq+eqh0NrN3Z\nSHtXLxDdip87rpB5FYXMGxd9TByVo8MkJaXp1H/xrYKsMMtnRFg+IwJAT28fm/a1sH5XE+t2NbFu\nVzN3vvQeXT3RW+rlZ4WYM7aAWWMKmDkmn5lj8pkxOp88DdeIz8S7hf4u0AA44Dbn3KrjLa8tdBkp\n3b19bN7XwrrqJt7a1cTGPc1s3ttCW2xLHqCiOJtZsYCfOaaAqZFcJpfmkpOhoJfkMlJDLmOdc7vN\nrAx4Aviic+75AcusBFYCTJgwYfGOHTuGvD6RePT1OXY1HuCdvS1s2tscm7awva6N3r4P/j8YW5jF\n5EguU0rzmBIL+amRPMYWZesoG/HEiB/lYmbfAlqdcz881jLaQpdk1NnTy/battijle11bdFHbSst\nHT2HlssIBZg0KocJJTlUFOcwviSH8cXZ0WlJjoZwZNgM+xi6meUCAedcS+z5hcC3h/p+Il7JDAWZ\nXV7A7PKCw9qdc9S1dvFu3QdB/25dGzvr23l52/7Dhm8ASnIzGF+cTUVJDuOLcxhfks3YwmzGFGYx\ntjCbguyQds7KsIpnk2I0cH/sAxoCfuucezQhVYkkATMjkp9JJD+TJZNLDnvNOUdDezc769vZ2dDO\nzvoDvF/fTnVDOxt2NfH4hr109x7+6zc7HKS8MIvyoizGFGQfel5e+MF8UU5YoS9DNuRAd85tBxYk\nsBaRlGFmlORmUJKbwYLxRUe83tvnqGnpYHdjB3ubOtjTdIA9TR88f2lbHfuaO+gbMOKZEQwQyc+k\nND+TSF7moS+USL/5sth8VliXRZDDadBPZBgEA0Z5YTblhdnHXKant4+61i52Nx2IBX0HtS2d0Udr\nJ9UN7azd2cD+ti6OtqsrPzN0KPxH5WZQnJsRneZkHPqy6f/QF4D/KdBFPBIKBhhTmMWYwqzjLtfT\n20d9Wxc1saA/FPoH55s72VLTSkNbFw3tXUds9R+UHQ4eCvfDwz9MYU4Ghdnhwx5F2WEKssM6sieF\nKNBFklwoGKCsIIuyguMHP0SHepoPdFPf3kV9W/TR0NbF/tj0YHtDWxfba6NfAgN37g6Unxmi4GDI\n5xwe+gVHacvPCpOXGSI/K0RmKKB9AiNIgS7iI8GAURzbAp8aGdy/6ezppelAN03t3dHpgEdjezfN\n/ea31rTSGHt+8GzcYwkHLRbuH4R89PHBfF5WiPzMI9sKYvN5WSHdBGWQFOgiaS4zFKQsP0hZ/ol/\nAQzU0d17+BdAezctnd20dvTQ0tlDS0dP9HlHN62dPTR39LC7sYOWzpZYew89xxojOqzGAHmZIXIy\ng+RmhMjNDJGTEX1+sC0nM0heRoiczBC5GcFD09zM0BHL5WaEfDmUpEAXkSHLCgfJCgcZPYjhoKNx\nztHZ00dzR/ehgG/tjH4BtPSbb+3soa2zh/au3kPTlo4e9jV30NbZS3tXD21dvSf8xXB47YHDgz4W\n/lnhINnhIDkZ0b5lZwTJiU2zM6KvZYf7Pc/4YNmcjBDZ4SBZYW+GmhToIuIZMzv0pVCWH//7dff2\n9Qv9Hto6e2nr6qH94DT22gdfAh+81tYZfa2utYuO7ujrB7p6OdDde8Q5BYMxMPT/9bK5nD5lVPyd\nPA4Fuoj4RjgYoDA7QGF2OKHv293bR0d376GAP9DdS3tXLx1d0enBtkOv95u2d/XS0d1LflZiazoa\nBbqIyAmEgwHCwcCIhHI8tOtYRMQnFOgiIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI\n+ETCbhI9qJWZ1QI7hvjPS4G6BJaTCtTn9KA+p4d4+jzROXfC62eOaKDHw8yqBnPXaz9Rn9OD+pwe\nRqLPGnIREfEJBbqIiE+kUqCv8roAD6jP6UF9Tg/D3ueUGUMXEZHjS6UtdBEROY6UCHQzW2Fmm8xs\nq5l93et6EsXM7jCzGjNb36+txMyeMLMtsWlxrN3M7P/F/gZvmdki7yofGjMbb2bPmNlGM9tgZjfF\n2n3bZwAzyzKz18zszVi//yXWPtnMXo31+/dmlhFrz4zNb429PsnL+ofKzIJmtsbMHorN+7q/AGb2\nnpmtM7O1ZlYVaxuxz3fSB7qZBYGfAh8FTgGuMbNTvK0qYe4EVgxo+zrwlHNuOvBUbB6i/Z8ee6wE\nfj5CNSZSD/CPzrnZwFLgC7H/ln7uM0AncK5zbgGwEFhhZkuB7wO3xPrdANwYW/5GoME5Nw24JbZc\nKroJ2Nhv3u/9PejDzrmF/Q5RHLnPt3MuqR/AGcBj/eZvBm72uq4E9m8SsL7f/CagPPa8HNgUe34b\ncM3RlkvVB/AgcEGa9TkHeAM4nehJJqFY+6HPOfAYcEbseSi2nHld+0n2syIWXucCDwHm5/726/d7\nQOmAthH7fCf9FjowDtjZb7461uZXo51zewBi07JYu6/+DrGf1acCr5IGfY4NP6wFaoAngG1Ao3Ou\nJ7ZI/74d6nfs9SZgeO8unHg/Br4K9MXmR+Hv/h7kgMfNbLWZrYy1jdjnOxXuKWpHaUvHQ3N883cw\nszzgXuDLzrlms6N1LbroUdpSss/OuV5goZkVAfcDs4+2WGya0v02s4uBGufcajM752DzURb1RX8H\nWOac221mZcATZvbOcZZNeL9TYQu9Ghjfb74C2O1RLSNhn5mVA8SmNbF2X/wdzCxMNMzvcs7dF2v2\ndZ/7c841As8S3YdQZGYHN6r69+1Qv2OvFwL1I1tpXJYBl5jZe8DviA67/Bj/9vcQ59zu2LSG6Bf3\nEkbw850Kgf46MD22hzwDuBr4k8c1Dac/ATfEnt9AdJz5YPunY3vGlwJNB3/GpQqLborfDmx0zv2o\n30u+7TOAmUViW+aYWTZwPtGdhc8AV8YWG9jvg3+PK4GnXWyQNRU45252zlU45yYR/f/1aefctfi0\nvweZWa6Z5R98DlwIrGckP99e70QY5I6Gi4DNRMcdv+F1PQns193AHqCb6Lf1jUTHDp8CtsSmJbFl\njejRPtuAdUCl1/UPob9nEf1J+RawNva4yM99jvVjPrAm1u/1wP+NtU8BXgO2An8EMmPtWbH5rbHX\np3jdhzj6fg7wUDr0N9a/N2OPDQezaiQ/3zpTVETEJ1JhyEVERAZBgS4i4hMKdBERn1Cgi4j4hAJd\nRMQnFOgiIj6hQBcR8QkFuoiIT/x/JcRltEUDKVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## train/test splits\n",
    "\n",
    "x_train, y_train = X[:100], y[:100]\n",
    "x_test, y_test = X[100:], y[100:]\n",
    "\n",
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _  = sess.run([cost, train_op], \n",
    "                         feed_dict={tf_x: x_train, \n",
    "                                    tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))\n",
    "            \n",
    "plt.plot(training_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing objects in a TensorFlow graph using their names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing variables and operators by their names is very useful in many scenarios. For example, we may develop a model in a separate module; and thus the variables are not available in a different Python scope according to Python scoping rules. However, if we have a graph, we can execute the nodes of the graph using their names in the graph. \n",
    "\n",
    "This can be done easily by changing the *sess.run* method from the previous code example, using the variable name of the **cost** in the graph rather than the Python variable *cost* by changing *sess.run([cost, train_op], ...)* to *sess.run(['cost:0', 'train_op'], ...)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: 12.2230\n",
      "Epoch   50: 8.3876\n",
      "Epoch  100: 6.5721\n",
      "Epoch  150: 5.6844\n",
      "Epoch  200: 5.2269\n",
      "Epoch  250: 4.9725\n",
      "Epoch  300: 4.8169\n",
      "Epoch  350: 4.7119\n",
      "Epoch  400: 4.6347\n",
      "Epoch  450: 4.5742\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMQnFOgiIj6hQBcR8QkFuoiIT/x/JcRltEUDKVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _  = sess.run(['cost:0', 'train_op'], \n",
    "                         feed_dict={'tf_x:0': x_train, \n",
    "                                    'tf_y:0': y_train})\n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))\n",
    "            \n",
    "plt.plot(training_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are evaluating the cost by its name, which is *'cost:0'*, and executing the train operator by its name: *'train_op'*. Also, in *feed_dict*, instead of using *tf_x: x_train*, we are using *'tf_x:0': x_train*. \n",
    "\n",
    "If we pay attention to the names of the tensors, we will notice that TensorFlow adds a sufix *':0'* to the name of the tensors. \n",
    "\n",
    "However, the names of operators do not have any suffix like that. When a tensor with a given name, such as *name='my_tensor'* is created, TensorFlow appends *':0'*; so the name of this tensor will be *'my_tensor:0'*.\n",
    "\n",
    "Then, if we try to create another tensor with the same name in the same graph, TensorFlow will append *'_1:0'* and so on to the name; therefore, the future tensors will be named *'my_tensor_1:0'*, *'my_tensor_2:0'*, and so on. This naming assumes that we are not trying to reuse the already created tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and restoring a model in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we built a graph and trained it. How about doing the actual prediction on the held out test set? The problem is that we did not save the model parameters; so, once the executing of the preceding statements are finished and we exit the *tf.Session* environment, all the variables and their allocated memories are freed. \n",
    "\n",
    "One solution is to train a model, and as soon as the training is finished, we can feed it our test set. However, this is not a good approach since deep neural network models are typically trained over multiple hours, days, or even weeks. \n",
    "\n",
    "The best approach is to save the trained model for future use. For this purpose, we need to add a new node to the Graph, an instance of the *tf.train.Saver* class, which we call *saver*. \n",
    "\n",
    "In the following statement, we can add more nodes to a particular graph. In this case, we are addding *saver* to the graph *g*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can retrain the model with an additional call to *saver.save()* to save the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: 12.2230\n",
      "Epoch   50: 8.3876\n",
      "Epoch  100: 6.5721\n",
      "Epoch  150: 5.6844\n",
      "Epoch  200: 5.2269\n",
      "Epoch  250: 4.9725\n",
      "Epoch  300: 4.8169\n",
      "Epoch  350: 4.7119\n",
      "Epoch  400: 4.6347\n",
      "Epoch  450: 4.5742\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _  = sess.run([cost, train_op], \n",
    "                         feed_dict={tf_x: x_train, \n",
    "                                    tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))\n",
    "            \n",
    "        saver.save(sess, './trained-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of this new statement, three files are created with extensions *.data*, *.index*, and *.meta*. TensorFlow uses Protocol Buffers, which is a language-agnostic way, for serializing structured data. \n",
    "\n",
    "Restoring a trained model requires two steps:\n",
    "\n",
    "1. Rebuild the graph that has the same nodes and names as the saved model.\n",
    "2. Restore the saved variables in a new *tf.Session* environment. \n",
    "\n",
    "For the first step, we can run the statements, as we did in the first place, to build the graph *g*. But there is a much easier way to do this. Note that all of the information regarding the graph is saved as metadata in the file with the *.meta* extension. Using the following code, we rebuild the graph by importing it from the meta file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tf.train.import_meta_graph* function recreates the graph that is saved in the *'./trained-model.meta'* file. After recreating the graph, we can use the *new_saver* object to restore the parameters of the model in that session and execute it. The complete code to run the model on a test set is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    \n",
    "    y_pred = sess.run('y_hat:0', feed_dict={'tf_x:0': x_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we evaluated $ŷ$ tensor by its name that was given previously: *'y_hat:0'*. Also, we needed to feed the values for the *tf_x* placeholder, which is also done by its name: *'tf_x:0'*. In this case, there is no need to feed the values for the true $y$ values. This is because executing the *y_hat* node does not depend on *tf_y* in the computation graph that we built. \n",
    "\n",
    "Now, let's visualize the predictions, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_arr = np.arange(-2, 4, 0.1)\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    \n",
    "    y_arr = sess.run('y_hat:0', feed_dict={'tf_x:0': x_arr})\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr.T[:, 0], '-r', lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and restoring a model is very often used during the training stage of large models as well. Since the training stage of large models can take several hours to days, we can break the training phase into smaller tasks. For example, if the intended number of epochs is 100, we can break it into 25 tasks, where each task would run four epochs one after the other. For this purpose, we can save the trained model and restore it in the next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Tensors as multidimensional data arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we explore a selection of operators that can be used to transform tensors. Note that some of these operators work very similar to NumPy array transformations. However, when we are dealing with tensors with ranks higher than 2, we need to be careful in using such transformations, for example, the transpose of a tensor. \n",
    "\n",
    "First, as in NumPy, we can use the attribute *arr.shape* to get the shape of a NumPy array. In TensorFlow, we use the *tf.get_shape* function instead: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T1:0\", shape=(3, 4), dtype=float64)\n",
      "Shape of T1 is  (3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    arr = np.array([[1., 2., 3., 3.5], \n",
    "                    [4., 5., 6., 6.5], \n",
    "                    [7., 8., 9., 9.5]])\n",
    "    T1 = tf.constant(arr, name='T1')\n",
    "    print(T1)\n",
    "    s = T1.get_shape()\n",
    "    print('Shape of T1 is ', s)\n",
    "    T2 = tf.Variable(tf.random_normal(shape=s))\n",
    "    print(T2)\n",
    "    T3 = tf.Variable(tf.random_normal(shape=(s.as_list()[0],)))\n",
    "    print(T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used *s* to create *T2*, but we cannot slice or index *s* for creating *T3*. Therefore, we converted *s* into a regular Python list by *s.as_list()* and then used the usual indexing conventions. \n",
    "\n",
    "Now, let's see how we can reshape tensors. Recall that in NumPy, we can use *np.reshape* or *arr.reshape* for this purpose. In TensorFlow, we use the function *tf.reshape* to reshape a tensor. As is the case for NumPy, one dimension can be set to -1 so that the size of the new dimension will be inferred based on the total size of the array and the other remaining dimensions that are specified. \n",
    "\n",
    "In the following code, we reshape the tensor *T1* to *T4* and *T5*, both of which have rank 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T4:0\", shape=(1, 1, 12), dtype=float64)\n",
      "Tensor(\"T5:0\", shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    T4 = tf.reshape(T1, shape=[1, 1, -1], name='T4')\n",
    "    print(T4)\n",
    "    \n",
    "    T5 = tf.reshape(T1, shape=[1, 3, -1], name='T5')\n",
    "    print(T5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's print the elements of *T4* and *T5*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]]\n",
      "\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(T4))\n",
    "    print()\n",
    "    print(sess.run(T5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, there are there ways to transpose an array in NumPy: *arr.T*, *arr.transpose()*, and *np.transpose(arr)*. In TensorFlow, we use the *tf.transpose* function instead, and in addition to a regular transpose operation, we can change the order of dimensions in any way we want by specifying the order in *perm=[...]*. Here is an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T6:0\", shape=(4, 3, 1), dtype=float64)\n",
      "Tensor(\"T7:0\", shape=(1, 4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    T6 = tf.transpose(T5, perm=[2, 1, 0], name='T6')\n",
    "    print(T6)\n",
    "    \n",
    "    T7 = tf.transpose(T5, perm=[0, 2, 1], name='T7')\n",
    "    print(T7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can also split a tensor into a list of subtensors using the *tf.split* function, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'T8:0' shape=(1, 3, 2) dtype=float64>, <tf.Tensor 'T8:1' shape=(1, 3, 2) dtype=float64>]\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    t5_split = tf.split(T5, num_or_size_splits=2, axis=2, name='T8')\n",
    "    print(t5_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is important to note that the output is not a tensor object anymore; rather, it is a list of tensors. The name of these subtensors are *'T8:0'* and *'T8:1'*. \n",
    "\n",
    "Lastly, another useful transformation is the concatenation of multiple tensors. If we have a list of tensors with the same shape and *dtype*, we can combine them into one big tensor using the *tf.concat* function. An example is given in the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"t1:0\", shape=(5, 1), dtype=float32)\n",
      "Tensor(\"t2:0\", shape=(5, 1), dtype=float32)\n",
      "Tensor(\"t3:0\", shape=(10, 1), dtype=float32)\n",
      "Tensor(\"t4:0\", shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    t1 = tf.ones(shape=(5, 1), dtype=tf.float32, name='t1')\n",
    "    t2 = tf.zeros(shape=(5, 1), dtype=tf.float32, name='t2')\n",
    "    print(t1)\n",
    "    print(t2)\n",
    "with g.as_default():\n",
    "    t3 = tf.concat([t1, t2], axis=0, name='t3')\n",
    "    print(t3)\n",
    "    t4 = tf.concat([t1, t2], axis=1, name='t4')\n",
    "    print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the values of these concatenated tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(t3.eval())\n",
    "    print()\n",
    "    print(t4.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing control flow mechanics in building graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's learn about an interesting TensorFlow mechanic. TensorFlow provides a mechanism for making decisions when building a graph. However, there are some subtle differences when we use Python's control flow statements compared to TensorFlow's control flow functions, when constructing computation graphs. \n",
    "\n",
    "To illustrate these differences with some simple code examples, let's consider implementing the following equation in TensorFlow: \n",
    "\n",
    "$$\n",
    "res = \n",
    "\\begin{cases}\n",
    "    x + y   &\\text{if}\\, x < y \\\\\n",
    "    x - y   &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In the following code, we may naively use Python's *if* statement to build a graph that corresponds to the preceding equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: Tensor(\"result_add:0\", dtype=float32)\n",
      "x < y: True -> Result: 3.0\n",
      "x < y: False -> Result: 3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, \n",
    "                          shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, \n",
    "                          shape=None, name='tf_y')\n",
    "    if x < y:\n",
    "        res = tf.add(tf_x, tf_y, name='result_add')\n",
    "    else:\n",
    "        res = tf.subtract(tf_x, tf_y, name='result_sub')\n",
    "    \n",
    "    print('Object:', res)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('x < y: %s -> Result:' % (x < y), res.eval(feed_dict={'tf_x:0': x, 'tf_y:0': y}))\n",
    "    x, y = 2.0, 1.0\n",
    "    print('x < y: %s -> Result:' % (x < y), res.eval(feed_dict={'tf_x:0': x, 'tf_y:0': y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the *res* object is a tensor named *'result_add:0'*. It is very important to understand that in the previous mechanism, the computation graph has only one branch associated with the addition operator, and the subtract operator has not been called. \n",
    "\n",
    "The TensorFlow computation graph is static, which means that once the computation graph is built, it remains unchanged during the executing process. So, even when we change the values of *x* and *y* and feed the new values to the graph, these new tensors will go through the same path in the graph. Therefore, in both cases, we see the same output 3.0 for $x=2,y=1$ and for $x=1,y=2$. \n",
    "\n",
    "Now, let's use the control flow mechanics in TensorFlow. In the following code, we implement the previous equation using the *tf.cond* function instead of Python's *if* statement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: Tensor(\"cond/Merge:0\", dtype=float32)\n",
      "x < y: True -> Result: 3.0\n",
      "x < y: False -> Result: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, shape=None, name='tf_y')\n",
    "    res = tf.cond(tf_x < tf_y, lambda: tf.add(tf_x, tf_y, name='result_add'), \n",
    "                               lambda: tf.subtract(tf_x, tf_y, name='result_sub'))\n",
    "    print('Object:', res)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('x < y: %s -> Result:' % (x < y), res.eval(feed_dict={'tf_x:0': x, 'tf_y:0': y}))\n",
    "    x, y = 2.0, 1.0\n",
    "    print('x < y: %s -> Result:' % (x < y), res.eval(feed_dict={'tf_x:0': x, 'tf_y:0': y}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the *res* object is named *'cond/Merge:0'*. In this case, the computation graph has two branches with a mechanism to decide which branch to follow at execution time. Therefore, when $x=2,y=1$, it follows the addition branch and the output will be 3.0, while for $x=1,y=2$, the subtraction branch is pursued and the result will be 1.0. \n",
    "\n",
    "The following figure contrast the differences in the computation graph of the previous implementation using the Python *if* statement versus TensorFlow's *tf.cond* function:\n",
    "\n",
    "<img src='images/14_06.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to *tf.cond*, TensorFlow offers several other control flow tensors, such as *tf.case* and *tf.while_loop*. For instance, *tf.case* is the TensorFlow control equivalent to a Python *if...else* statement. Consider the following Python expression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (x < y):\n",
    "    result = 1\n",
    "else:\n",
    "    result = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tf.case* equivalent to the previous statement for conditional execution in a TensorFlow graph would then be implemented as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda: tf.constant(1)\n",
    "f2 = lambda: tf.constant(0)\n",
    "result = tf.case([(tf.less(x, y), f1)], default=f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can add a *while* loop to a TensorFlow graph that increments the *i* variable until a threshold value (*threshold*) is reached, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant(0)\n",
    "threshold = 100\n",
    "c = lambda i: tf.less(i, 100)\n",
    "b = lambda i: tf.add(i ,1)\n",
    "t = tf.while_loop(cond=c, body=b, loop_vars=[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the graph with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great feature of TensorFlow is TensorBoard, which is a module for visualizing the graph as well as visualizing the learning of a model. Visualizing the graph allows us to see the connection between nodes, explore their dependencies, and debug the model if needed. \n",
    "\n",
    "So let's visualize a network that we have already built, one which consists of a generator and a classifier part. We will repeat some code that we previously used for defining the helper functions. So, revisit the *Reusing variables* section earlier in this chapter, for the function definitions of *build_generator* and *build_classifier*. Using these two helper functions, we will build the graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100), \n",
    "                          dtype=tf.float32, \n",
    "                          name='tf_X')\n",
    "    ## build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "        \n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        ## classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X, labels=tf.ones(shape=batch_size))\n",
    "        ## reuse the classifier for generated data\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels=tf.zeros(shape=batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that no changes were needed so far for building the graph. So after building the graph, its visualization is straighforward. The following lines of code export the graph for visualization purposes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    file_writer = tf.summary.FileWriter(logdir='./logs/', graph=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new directory: *logs/*. Now, we just need to run the following command in a terminal: \n",
    "\n",
    "**tensorboard --logdir logs**\n",
    "\n",
    "This command will print a message, which is a URL address. You can try launching TensorBoard by copying the link and pasting it into your browser's address bar. You should see the graph that corresponds to this model, as shown in the following figure: \n",
    "\n",
    "<img src='images/14_07.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large rectangular boxes indicate the two subnetworks that we built: generator and classifier. Since we used the *tf.variable_scope* function when we built this graph, all the components of each of these subnetworks are grouped into those rectangular boxes, as shown in the previous figure. \n",
    "\n",
    "We can expand these boxes to explore their details: using your mouse, click on the plus sign on the top-right corner of these boxes to expand them. Doing this, we can see the details of the generator subnetwork, as shown in the following figure:\n",
    "\n",
    "<img src='images/14_08.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By exploring this graph, we can easily see that the generator has two weight tensors, named *w1* and *w2*. Next, let's expand the classifier subnetwork, as shown in the following figure:\n",
    "\n",
    "<img src='images/14_09.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this figure, the classifier has two sources of input, where one input comes from the *tf_X* placeholder and the other one is in fact the output of the generator subnetwork. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending your TensorBoard experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an interesting exercise, we suggest you use TensorBoard to visualize the different graphs we implemented throughout this chapter. For example, you could use similar steps for building the graphs, and then add extra lines for their visualization. You can also make graphs for the control flow section, which will show you the difference between graphs made by the Python *if* statement and the *tf.cond* function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we covered in detail the key features and concepts of TensorFlow. We started with discussing TensorFlow's main features and advantages, and key TensorFlow concepts such as ranks and tensors. We then looked at TensorFlow's computation graphs, and discussed how to launch a graph in a session environment, and you learned about placeholders and variables. We then saw different ways to evaluate tensors and execute operators, using Python variables, or by referring to them via their name in the graph. \n",
    "\n",
    "We went further to explore some of the essential TensorFlow operators and functions for transforming tensors, such as *tf.transpose*, *tf.reshape*, *tf.split*, and *tf.concat*. Finally, we saw how to visualize a TensorFlow computation graph using TensorBoard. Visualizing computation graphs using this module can be very useful, especially when we are debugging complex models. \n",
    "\n",
    "In the next chapter, we will make use of this library to implement an advanced image classifier: a **Convolutional Neural Network (CNN)**. CNNS are powerful models and have shown great performance in image classification and computer vision. We will cover the basic operations in CNNs, and we will implement deep convolutional networks for image classification using TensorFlow. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
